{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B78gqH_mtbHA"
   },
   "source": [
    "------------------------------------------------------\n",
    "*Applications of Machine Learning*\n",
    "------------------------------------------------------\n",
    "\n",
    "*Vanessa GÃ³mez Verdejo vanessa@tsc.uc3m.es*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EbEvK3yZIxU4"
   },
   "source": [
    "# Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2gBoedLYoRl"
   },
   "source": [
    "# 1. Introduction\n",
    "\n",
    "Recommender systems are one of the most common and easily understandable applications within machine learning and data science.\n",
    "\n",
    "Based on information about users and contents (or items) and the preferences or tastes that users have for different contents, recommender systems make predictions about the interest that a user may have in new products that he may not have shown interest  in  (or bought) yet. This is called **personalised recommendations**.\n",
    "\n",
    "Due to the large amount of information that surrounds us, many companies have chosen to include these systems within their services to cope with this information and provide the user with personalised recommendations, content, and/or services.\n",
    "\n",
    "Some examples of these systems, with which we already naturally coexist, can be found in the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ri6ujxDZ_QzG"
   },
   "source": [
    "1. **AMAZON**\n",
    "\n",
    "The online shopping giant incorporates a personalised recommendation algorithm on its website. When a user is interested in a product, the system provides two lists: the first related to the product search and the second with a set of products that may also be of interest to them based on their purchase history...\n",
    "\n",
    "<img align=\"center\" src=\"http://www.tsc.uc3m.es/~vanessa/Figs_notebooks/ML/SR/Amazon.png\" width=60%>\n",
    "\n",
    "\n",
    "The aim of this system is to increase sales. In fact, Amazon has stated that 30% of its average sales are generated by recommendations.\n",
    "\n",
    "What is Amazon's basis for generating this personalised list of recommendations? And how does it manage to do it efficiently with the large number of users and products it has to handle?\n",
    "\n",
    "The idea is quite simple: for each product, Amazon generates a list of similar products that may be of interest along with this product. To do this, it analyzes the products that users have purchased in the same order, or added to the shopping cart, or simply stored in a their wish list. \n",
    "\n",
    "Amazon does not look at the characteristics of the products to see if one product is similar to another, but analyzes the users' preferences for the products to generate these similarities. In other words, if a user buys an iPad and jointly buys a case, when a new user buys the iPad, Amazon will recommend buying the case. This is what is known as recommendation systems based on **collaborative filtering**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ah-wXHLssG21"
   },
   "source": [
    "2. **SPOTIFY**\n",
    "\n",
    "Spotify not only provides a platform to access all the music we want to listen to with great ease and speed, but since 2015 it also offers a weekly playlist with personalised recommendations. \n",
    "\n",
    "<img align=\"centre\" src=\"http://www.tsc.uc3m.es/~vanessa/Figs_notebooks/ML/SR/Spotify.png\" width=60%>\n",
    "\n",
    "In this case, the aim is not to increase sales, but to build user loyalty by preventing users from getting tired of always listening to the same thing. In fact, Spotify states that 70% of its plays come from these recommendations.\n",
    "\n",
    "To design this recommendation system, Spotify combines 3 recommendation models:\n",
    "1. Collaborative Filtering Models: they analyse users' tastes to recommend similar songs.\n",
    "2. Natural Language Processing Models: analyse the information available on the Internet about the groups and/or songs to detect trends.\n",
    "3. Audio models: analyse raw audio tracks to look for similarities between musical genres to help improve recommendations.\n",
    "\n",
    "The combination of these 3 models gives rise to the Spotify recommender, which has earned the loyalty of many customers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZS1eD6gtYoK"
   },
   "source": [
    "3. **NETFLIX**.\n",
    "\n",
    "Netflix also includes a personalised recommendation system to help users find series and films that interest them. \n",
    "\n",
    "<img align=\"centre\" src=\"http://www.tsc.uc3m.es/~vanessa/Figs_notebooks/ML/SR/netflix.jpg\" width=60%>\n",
    "\n",
    "To design this system Netflix uses the information about users and content:\n",
    "* View history together to the ratings over the already viewed  content. \n",
    "* Tastes and preferences of other users of the system.\n",
    "* Information about the content: titles, genre, categories, actors, year of release, etc.\n",
    "* User behaviour: time of day watched, devices, time spent using the system.\n",
    "\n",
    "All this data feeds the recommendation system so that, combining schemes based on collaborative filtering and others based on content and user information, it can give personalised recommendations to users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5KzVS3_tz1s"
   },
   "source": [
    "## Goals of this session\n",
    "\n",
    "* Learn the main techniques for the design of recommender systems. We will pay special attention to collaborative filtering systems.\n",
    "* Become familiar with the (python) libraries that can help us to design them. In particular, we will use the Surprise library that implements the most common collaborative filtering models.\n",
    "* Learn how to design these models, properly validate their parameters, and evaluate their performance.\n",
    "* Analyse the advantages and disadvantages of each of these methods.\n",
    "\n",
    "To do this, in the following sections, we will go through a practical study case and we will design different recommendation systems.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8MueV1SwHiX"
   },
   "source": [
    "# 2. Starting information: the database\n",
    "\n",
    "For the design of recommender systems, we  usually have the following available information:\n",
    "\n",
    "* Metadata or **descriptive** information **of the contents**.\n",
    "* Sociodemographic **information of the users**.\n",
    "* **Ratings** or user evaluation of the content. These ratings can be explicit or implicit:\n",
    "  - Explicit information: when the user has rated a content by giving a specific score (e.g. a value on a scale from 1 to 5).\n",
    "  - Implicit information: in some applications it is very difficult to ask the user to vote on content; in these cases, the user's browsing or system usage history can be followed to find out the user interests (pages visited, content previewed, number of times a song is listened to, etc.).\n",
    "\n",
    "The main difficulty in designing these systems is that most of this information is not available. In fact, the main objective of these systems is to predict the ratings that users would give to content that they have not rated yet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3e_vxsgpKPRS"
   },
   "source": [
    "## **Book-Crossing dataset**\n",
    "For this session we will work with a book recommendation database: [Book-Crossing](http://www2.informatik.uni-freiburg.de/~cziegler/BX/)\n",
    "\n",
    "This database contains information from 278,858 users (anonymised but with demographic information) who provide 1,149,780 ratings of some 271,379 books. This information is structured in 3 tables (or .csv files):\n",
    "\n",
    "* **User table**: It contains the users' information: an identifier and if available some demographic data such as location and age. As this information has been anonymised, the user identifiers are integers.  \n",
    "* **Book table**: For each book, its identifier (in this case the ISBN) and additional metadata such as book title, author, year of publication and publisher are provided.\n",
    "* **Rating table**: It contains the information with the ratings that users have given to some books. The ratings are explicit and implicit. The explicit ratings are expressed on a scale from 1 to 10 (higher values denoting greater interest), and the implicit ratings are indicated with a value of 0.\n",
    "\n",
    "Let's load the database and analyse the content in each of these matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-uLoCD4nP_G"
   },
   "source": [
    "### Rating matrix\n",
    "\n",
    "The score table is usually a matrix like this\n",
    "\n",
    "\n",
    "<img align=\"centre\" src=\"http://www.tsc.uc3m.es/~vanessa/Figs_notebooks/ML/SR/Ratings.png\" width=40%>\n",
    "\n",
    "where most of the elements are not available. In other words, it is a very sparse matrix (usually only 1%-5% of the data is known). For this reason, this matrix is usually stored in a `(user_id, item_id, rating)` format. To see what this matrix looks like, let's start by loading the rating table and analysing how its values are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kMbFO-Qk2NE-",
    "outputId": "c4688700-934b-4a79-b7b1-09363ab3b04e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None # To silect warning in chained_assignment\n",
    "\n",
    "# Load the data file\n",
    "url_ratings = \"http://www.tsc.uc3m.es/~vanessa/Figs_notebooks/ML/SR/BX-Book-Ratings.csv\"\n",
    "\n",
    "rating = pd.read_csv(url_ratings, sep=';', error_bad_lines=False, encoding=\"latin-1\")\n",
    "rating.columns = ['userID', 'bookID', 'bookRating']\n",
    "rating.drop_duplicates(inplace=True)\n",
    "# Check the data table and get some information\n",
    "print('Number of entries in the rating table:',rating.shape[0])\n",
    "print('Number of users:', len(rating.userID.unique()))\n",
    "print('Number of books (items):', len(rating.bookID.unique()))\n",
    "print('Maximum rating value:', rating.bookRating.max())\n",
    "print('Minimum rating value:', rating.bookRating.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "UxAvXj-ov-GX",
    "outputId": "3334bb1a-3346-4606-dd63-bacf2d339249"
   },
   "outputs": [],
   "source": [
    "rating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Td0Raa_VwD0q"
   },
   "source": [
    "The structure of this table is a tuple (`userID`, `bookID`, `rating`). The table collects one entry for each rating issued. Users who have not rated any book (e.g. new users in the system) have no entry in this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McC39lrIAJnp"
   },
   "source": [
    "Rating distribution: What score values are there? Let's draw its histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "BQZlHYpBAI7w",
    "outputId": "012ddfc9-2fff-470a-effc-c5a4fde08374"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rating_distribution = rating.bookRating\n",
    "plt.hist(rating_distribution)\n",
    "plt.ylabel('Number of ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MM-Tv3IEvSpO"
   },
   "source": [
    "We can see that the majority of the ratings (700K out of 1200K scores in total) are 0 (implicit scores), and very few scores are 1, 2 or 3. In general, if a book achieves low scores it means that it has not been liked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FtYt1lldk9pY"
   },
   "source": [
    "How many books has each user rated? To answer this question, let's draw the distribution of scores per user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "tkewS9b71tZH",
    "outputId": "8b507972-1339-4bf3-fdd3-c871aabbec3b"
   },
   "outputs": [],
   "source": [
    "# Count the number of entries in the rating matrix by user\n",
    "Nrating_por_user = rating.userID.value_counts()\n",
    "plt.hist(Nrating_por_user, range(20))\n",
    "plt.ylim([1, 60000])\n",
    "plt.xlim([1, 20])\n",
    "plt.ylabel('Number of users')\n",
    "plt.xlabel('Number of ratings')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"The user who has rated most books has rated:\", Nrating_por_user.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pka48jF0tpLG"
   },
   "source": [
    "We see that this distribution has many values at the beginning and then shows a long tail... this shows that many users have rated very few books and there are few users with many rated books. Although there is one user who has rated 13602 books!!!!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Oi_y_-ilQdx"
   },
   "source": [
    "And how many scores do we have for each book? Let's now show the distribution of ratings per book.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "7jUqixmXlr7t",
    "outputId": "2bd17639-5386-46f6-dffc-9f24c6d9bb80"
   },
   "outputs": [],
   "source": [
    "Nrating_por_book = rating.bookID.value_counts()\n",
    "plt.hist(Nrating_por_book, range(20))\n",
    "plt.ylim([1, 200000])\n",
    "plt.xlim([1, 20])\n",
    "plt.ylabel('Number of books')\n",
    "plt.xlabel('Number of ratings')\n",
    "plt.show()\n",
    "\n",
    "print(\"The highest rated book has:\", Nrating_por_book.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNBLiPWZuqhG"
   },
   "source": [
    "We now see a similar distribution where most of the books received less than 5 ratings, and very few books have many ratings, although the highest rated book has received 2.502 ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mk2Q8DmDnXE6"
   },
   "source": [
    "### Table of contents (books)\n",
    "\n",
    "Let's now analyse the information in this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2nCXVEPInhOn",
    "outputId": "7aae94bb-2e83-4413-f94b-444cd8d3186b"
   },
   "outputs": [],
   "source": [
    "url_books = \"http://www.tsc.uc3m.es/~vanessa/Figs_notebooks/ML/SR/BX-Books.csv\"\n",
    "\n",
    "books = pd.read_csv(url_books, sep=';', error_bad_lines=False, encoding=\"latin-1\", usecols=[\"ISBN\", \"Book-Title\", \"Book-Author\", \"Year-Of-Publication\"], low_memory=False)\n",
    "books.columns = ['bookID', 'title', 'author', 'year']  \n",
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGvMZ8v_vqEG"
   },
   "source": [
    "In this case each row of the table is associated to a book and has the information of the book (ID, title, author and year)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fai5sDEtrpnq"
   },
   "source": [
    "### User table\n",
    "\n",
    "Let's now analyse the information in the user table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "P4rqcC7K8yQe",
    "outputId": "991f337d-89ca-481b-d341-be6e17bb4677"
   },
   "outputs": [],
   "source": [
    "url_users = \"http://www.tsc.uc3m.es/~vanessa/Figs_notebooks/ML/SR/BX-Users.csv\"\n",
    "\n",
    "users = pd.read_csv(url_users, sep=';', error_bad_lines=False, encoding=\"latin-1\")\n",
    "users.columns = ['userID', 'localication', 'age']  \n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCdZXcNWwxVF"
   },
   "source": [
    "As in the content table, each row of the table is associated to a user and has the user's information. In this case their ID, location and year. We see that some fields are not available for some users and are listed as `NaN`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CYyzNWDwH5d"
   },
   "source": [
    "### Data preprocessing\n",
    "\n",
    "Before starting to work with this database, we are going to filter some of its fields based on two criteria:\n",
    "\n",
    "1. We are going to eliminate implicit scores. Most of the models that we are going to see only work with explicit scores, so we are going to eliminate the implicit scores to facilitate the design of the models.\n",
    "\n",
    "2. To reduce the size of the dataset, and avoid running into long runs, we are going to filter out books with few ratings and users who have scored few books. In fact, these users/books were not going to give us good results, so by eliminating them we facilitate the analysis of the methods we are going to study.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kacv8gWZnwT0",
    "outputId": "7729cf21-ac54-493e-c539-fa4b9e880c91"
   },
   "outputs": [],
   "source": [
    "print('The size of the original rating matrix is:\\t{}'.format(rating.shape))\n",
    "print('The size of the original user matrix is:\\t{}'.format(users.shape))\n",
    "print('The size of the original content matrix is:\\t{}'.format(books.shape))\n",
    "\n",
    "# 1. Remove implicit ratings\n",
    "\n",
    "rating = rating[rating.bookRating>0]\n",
    "\n",
    "# 2. Remove users and books with a low number of ratings\n",
    "\n",
    "min_book_ratings = 50\n",
    "filter_books = rating.bookID.value_counts() > min_book_ratings\n",
    "filter_books = filter_books[filter_books].index.tolist()\n",
    "\n",
    "min_user_ratings = 50\n",
    "filter_users = rating.userID.value_counts() > min_user_ratings\n",
    "filter_users = filter_users[filter_users].index.tolist()\n",
    "\n",
    "rating = rating[(rating.bookID.isin(filter_books)) & (rating.userID.isin(filter_users))]\n",
    "print('The size of the filtered rating matrix is:\\t{}'.format(rating.shape))\n",
    "\n",
    "users = users[(users.userID.isin(filter_users))]\n",
    "print('The size of the filtered user matrix is:\\t{}'.format(users.shape))\n",
    "\n",
    "books = books[(books.bookID.isin(filter_books))]\n",
    "print('The size of the filtered content matrix is:\\t{}'.format(books.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlSQIMXZT-0W"
   },
   "source": [
    "# 3. Recommender systems: what are they and how are they classified?\n",
    "\n",
    "As we have seen, recommender systems start from information about the contents (`books`), the users (`users`) and the users' interests in some of the contents (`rating`) in order to predict the users' interest in the unrated articles. In other words, fill in the blanks in the rating table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gkVQGcoRK8yB"
   },
   "source": [
    "Depending on the used information and how this information is used, we can classify recommender systems as:\n",
    "\n",
    "*  **Popularity-based models**: these systems only consider the content popularity  (based on user ratings, number of sales,...). They are easy to implement and enjoy a certain level of effectiveness, but they do not provide personalised recommendations (they do not take into account the personal preferences of each user).\n",
    "\n",
    "*  **Content-based systems**: the user is recommended similar items to those he liked in the past: \"Show me more of the same items that I liked\". This similarity between contents is done on the basis of the descriptions and characteristics of the contents (information about the books: similar title, same author, ...).\n",
    "\n",
    "* **User-based systems**: a user is recommended based on the tastes of users with a similar socio-demographic profile (this approach is not usually used).\n",
    "\n",
    "* **Collaborative filtering**: the user is recommended with items that were liked (in the past) by people with similar tastes and preferences. In other words, items rated positively by users who tend to agree with the user are recommended to the user.\n",
    "\n",
    "* **Hybrids**: combine the above schemes to exploit the advantages and overcome limitations of the different approaches.\n",
    "\n",
    "Two of the most popular approaches to recommender systems are collaborative filtering and content-based recommendations. In this notebook we are going to focus on collaborative filtering systems (the most common); but first let's review a couple of simple approaches to design a popularity-based system and a content-based system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ueYWukCuca5p"
   },
   "source": [
    "## 3.1 Popularity-based systems\n",
    "\n",
    "As mentioned above, one of the simplest recommendation methods are popularity-based systems. This approach recommends the most important items based on a certain metric or score (popularity). \n",
    "\n",
    "In this section, we are going to design one of these systems for our book recommendation database. To do so, we will follow the steps below:\n",
    "1. Select a popularity criterion, metric or score to rate the books.\n",
    "2. Calculate the popularity of each book.\n",
    "3. Sort the books according to their popularity to generate a list of recommendations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1Ii3qle_yYb"
   },
   "source": [
    "One of the simplest metrics could be to consider the average rating to each book or directly select the books with a high number of scores.\n",
    "\n",
    "Let's analyze these two metrics. To do so, complete the following exercises:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lG4Ibyui3zQo"
   },
   "source": [
    "**Exercise 1**: Calculate the average rating for each book and show the 10 books with the highest average rating.\n",
    "\n",
    "**Exercise 2**: Calculate the number of ratings for each book and display the 10 books with the highest number of ratings.\n",
    "\n",
    "If you find it useful, you can use the `groupby` and `agg` functions of the `dataframes` (you can find their help [here](https://pandas.pydata.org/pandas-docs/version/0.23.1/generated/pandas.core.groupby.DataFrameGroupBy.agg.html) and [here](https://pandas.pydata.org/pandas-docs/version/0.23.1/api.html#id39)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eg9UgNJl5GFv"
   },
   "source": [
    "####Â Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "9Yn8EdAwcZ9o",
    "outputId": "b8a67f4e-6fa4-4a97-c0a2-cddb7b34ca69"
   },
   "outputs": [],
   "source": [
    "# Exercise 1\n",
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "lXTWB30SF66y",
    "outputId": "9c9dc05e-ea91-409b-cb34-2210e5f81ca2"
   },
   "outputs": [],
   "source": [
    "# Exercise 2\n",
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGNdU66wAHuM"
   },
   "source": [
    "**Designing our popularity metric**.\n",
    "\n",
    "What are the potential drawbacks of the above metrics? \n",
    "\n",
    "* Using only the number of ratings we see that it doesn't make much sense because the most rated books can have bad ratings.\n",
    "\n",
    "* But using the average rating can give us problems because some books can have a very high score and be unreliable because they have few ratings... For example, \"The Curious Incident of the Dog in the Night-T...\" has a 9.3 with only 10 votes, and \"Harry Potter and the Goblet of Fire\" has an average score of 9.19 with 63 votes. Which would you recommend first with a highest confidence? \t\n",
    "\n",
    "    \n",
    "Looking at this, it seems most appropriate to use a metric that takes into account both the average rating and the accumulated number of votes. This system will ensure that, for example, a book with an average score of 6 with 500 votes will get a (much) higher score than a film with the same score but only a few votes.\n",
    "\n",
    "IMDB ([Internet Movie Database](https://www.imdb.com/)) assigns the popularity of its films with this formula:\n",
    "$$ {\\rm Weighted~Rating~(WR)}=\\frac{v}{v+m}R+\\frac{m}{v+m}C$$\n",
    "where,\n",
    "   * $v$ is the number of ratings;\n",
    "   * $m$ is the minimum number of votes required for its average rating to be significant;\n",
    "   * $R$ average rating;\n",
    "   * $C$ average rating over all items.\n",
    "\n",
    "If $v>>m$, ${\\rm WR} = R$, having many ratings we rely on its average rating; but if $m>>v$, ${\\rm WR} = C$, we do not rely on the ratings and the assigned popularity is the average of the whole database.\n",
    "\n",
    "Let's calculate this metric for our book collection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pkRkfcA69yQ"
   },
   "source": [
    "**Exercise 3**: Calculate the WR index for each of the books of our database and show the 10 books with the highest index. Set the value of $m$ to 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PoWNm1LU7TMY"
   },
   "source": [
    "####Â Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "6tn41ZL2caFv",
    "outputId": "5493e2ec-3143-4efe-c671-565d37fc8a26"
   },
   "outputs": [],
   "source": [
    "# m fixed to 10\n",
    "m = 10\n",
    "\n",
    "#<SOL>\n",
    "#</SOL>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "nVzo4FFVwSuc",
    "outputId": "62cf8f66-eb4e-4f28-f38f-4b6be0d4a060"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# To plot the result\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.barplot(x='WR',y='title', data=book_rating.head(20))\n",
    "\n",
    "plt.title('Libros mÃ¡s populares', weight='bold')\n",
    "plt.xlabel('Ãndice WR', weight='bold')\n",
    "plt.ylabel('TÃ­tulo', weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "xatEngOSUmlc",
    "outputId": "6c6b79fa-54f9-4dd7-c236-34a0d640353d"
   },
   "outputs": [],
   "source": [
    "# To print the result\n",
    "book_rating.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqlAcS44kMGc"
   },
   "source": [
    "## 3.2 Content-based systems\n",
    "\n",
    "In this section we are going to review content based systems. In this case, given a user, we are going to recommend books similar to the books he has already liked. To obtain the book similarities, we will use the descriptive information of each book. If we look at the `books` table, we see that we have the following information:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "_b3IXPujW3x1",
    "outputId": "a2a3a43a-24ef-4e2d-9325-e4572ffbe15e"
   },
   "outputs": [],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7IyAxuJbW3PB"
   },
   "source": [
    "* **Title**: we could analyse the semantic content of the titles to find books with similar topics. In fact, for this type of processing it would be interesting to have a summary of the book that is more descriptive of its content and, then, you can use many of the approaches learnt in the NLP block (topic models, word2vec, ...).\n",
    "* **Author**: in this case we can directly say that two books are similar if they were written by the same author.\n",
    "* **Year**: we could consider the year as another similarity variable, although it would only make sense if we combine it with any of the previous criteria.\n",
    "\n",
    "With this information and to build a simple system (not including NLP methods), we can apply the following criterion to build a list of similar books: \"*two books are similar if they are by the same author and are more similar if they have been published closer in time*\".\n",
    "\n",
    "To build this system let's solve the following exercises:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9Y-e5VKWsO8"
   },
   "source": [
    "### **Exercise 4**\n",
    "Complete the following code cell to given a `bookID`, build a dataframe (`books_author`) with all the books of the `bookID` author.\n",
    "\n",
    "*Note*: you can use the `.loc()` method of the DataFrames to make selection of rows that meet a certain condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3i6jSeTVo68E"
   },
   "source": [
    "####Â Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "F7fMO2X3caTc",
    "outputId": "935ca3b8-fb48-48f7-cef9-a70765db998a"
   },
   "outputs": [],
   "source": [
    "bookId = '0345402871'\t\n",
    "\n",
    "# Preprocess authors: convert all characters to lowercase\n",
    "books['author'] = books['author'].str.lower()\n",
    "\n",
    "#<SOL>\n",
    "#</SOL>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZamlXsHo-6-x"
   },
   "source": [
    "###**Exercise 5**\n",
    "For the `books_author` dataframe include a new column with the difference in years between the `bookId` publication year and the rest of the books in the dataframe. Then, build the `similar_books` dataframe by sorting the rows of `books_author` so that the books closest in time to `bookID` come first. It may be advisable to remove the reference book entry (the row with `bookID='0345402871'`) from this dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NaT_LvWSpD-A"
   },
   "source": [
    "####Â Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "bj7v_dxO4myr",
    "outputId": "df3cbd40-dd1d-4333-8bf5-7a9e93c6c00e"
   },
   "outputs": [],
   "source": [
    "# Preprocess years: convert to integer\n",
    "books_author['year'] = books_author['year'].astype(int)\n",
    "\n",
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDYdcF3E96WI"
   },
   "source": [
    "**Exercise 6**\n",
    "Let's now combine the solutions of Exercises 4 and 5 to build a function that, given a `bookId`, returns the list of most similar books (by the same author and closest in time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1P-ehebpIJM"
   },
   "source": [
    "####Â Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "osPbdxQjWlJq",
    "outputId": "d0c9a0ae-428a-4484-84e4-aa0cd186e234"
   },
   "outputs": [],
   "source": [
    "def find_similar_books(bookId):\n",
    "  #<SOL>\n",
    "  #</SOL>\n",
    "  return similar_books\n",
    "\n",
    "bookId = '0345402871'\t\n",
    "\n",
    "similar_books = find_similar_books(bookId)\n",
    "\n",
    "similar_books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoLkGZcWmxSg"
   },
   "source": [
    "### And how do we make recommendations to a user?\n",
    "\n",
    "Now that we know how to find similar books, we just need to look at the books that the user has previously rated a positive (he liked them) in order to recommend the books similiar to these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6R1hMTJnyjkY",
    "outputId": "e615a2c7-50f2-44f0-c862-1454a995a287"
   },
   "outputs": [],
   "source": [
    "rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "cqmw8JGtm_5-",
    "outputId": "84f13435-9279-4d61-dd40-3b12bdfad957"
   },
   "outputs": [],
   "source": [
    "# We choose a user and see their previous likes and dislikes.\n",
    "\n",
    "userId = 277427\n",
    "\n",
    "ratings_userID = rating.loc[rating['userID'] == userId]\n",
    "ratings_userID.sort_values(ascending=False,by=['bookRating']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SYveOmmy7Hw"
   },
   "source": [
    "We see that this user really liked the books: `002542730X`, `0345413903`, ..., `0743412028` so we can recommend books similar to these..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lxy5qozBzKbE",
    "outputId": "aca7b251-62d2-4f1e-9de2-afbd080cd9c8"
   },
   "outputs": [],
   "source": [
    "list_books = ['002542730X', '0345413903', '0061009059', '0385486804', '0399501487', '0553280368', '0679731148', '0743412028']\n",
    "for bookId in  list_books:\n",
    "  title = books.loc[books['bookID'] == bookId]['title']\n",
    "\n",
    "  print('Libros parecidos a '+title+':' )\n",
    "  similar_books = find_similar_books(bookId)\n",
    "  print(similar_books['title'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-fit6YxcYnM"
   },
   "source": [
    "# Collaborative filtering\n",
    "\n",
    "Collaborative filtering systems look for similarities between users/contents based on the ratings that users have given to the contents. They do not make use of user demographic information or metadata associated with the contents.\n",
    "\n",
    "These systems are divided into two types:\n",
    "\n",
    "1. **User-based filtering**: these systems make recomendations to a user based in the contents liked by users with similar preferences. For example, let's say Alice and Mary have similar tastes in books (i.e. they largely like and dislike the same books). Let's say a new book has been released and Alice has read it and liked it. Therefore, it is very likely that Mary would also like it, and therefore, the system would recommend this book to Mary.\n",
    "\n",
    "2. **Content-based filtering**: these systems are similar to the system we have just designed (content-based), except for the fact that the similarities between the contents (or items) are calculated based on the ratings given to them by the users. For example, if Alice, Mary and Anne have given 5 stars to the Harry Potter and Twilight books, the system identifies the items as similar. Therefore, if someone buys one of the Harry Potter books, the system also recommends the Twilight saga.\n",
    "\n",
    "To design these systems we only need the rating matrix!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2V_wzFwjleY"
   },
   "source": [
    "## 4.1 User-based collaborative filtering\n",
    "\n",
    "Given the \"active user\" (Alice) and an item ($i$) that she has not yet seen, these systems work as follows:\n",
    "1. They find the set of users who are most similar to Alice (they liked similar objects) and, in addition, have rated the item $i$.\n",
    "2. Then, to predict the rating that Alice would give  to the item $i$, they use the average of the ratings that these users (those who have similar preferences to Alice) have given to item $i$.\n",
    "\n",
    "Applying this process on all the objects that Alice has not rated yet, we could obtain some predictions of their scores with which we can make a ranking and, then, recommend to Alice the ones that we believe would have a higher rating.\n",
    "\n",
    "Let's see in detail how to carry out this process with the following example:\n",
    "\n",
    "<img align=\"center\" src=\"http://www.tsc.uc3m.es/~vanessa/Figs_notebooks/ML/SR/CF_user2user_1.png\" width=60% >\n",
    "\n",
    "\n",
    "**Step 1**: Let's calculate the similarity between users. \n",
    "\n",
    "To measure whether two users $u$ and $v$ are similar, it is common to use the correlation coefficient between the vectors of common scores, i.e., given the subset ($I_{u,v}$) of items that both users have scored, their similarity is given by:\n",
    "$${\\rm sim}(u,v) = \\frac{\\sum_{i \\in I_{u,v}}  r_{u,i}  r_{v,i}  }{\\sqrt{\\sum_{i \\in I_{u,v}} r_{u,i}^2  \\sum_{i \\in I_{u,v}}r_{v,i}^2}}$$\n",
    "where $r_{u,i}$ is the score that user $u$ has given to item $i$. Thus, we can have that Alice has the following similarities with the rest of the users:\n",
    "\n",
    "<img align=\"centre\" src=\"http://www.tsc.uc3m.es/~vanessa/Figs_notebooks/ML/SR/CF_user2user_2.png\" width=80%>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Step 2**: Let's make predictions about the ratings.\n",
    "\n",
    "Now to find out the rating that Alice would give to Item 5 we can take the most similar users to Alice ($N_A$) and average the scores that these users have given to Item 5, weighting them by their similarities, i.e.:\n",
    "$$ \\hat{r}_{A,Item5} = \\frac{\\sum_{v \\in N_A} {\\rm sim}(A,v) ~r_{v,Item5} }{\\sum_{v \\in N_A} {\\rm sim}(A,v)} $$\n",
    "\n",
    "In our example, we only use users 1 and 2 as similar users, so we would have:\n",
    "$$ \\hat{r}_{A,Item5} = \\frac{0.85-3 + 0.7-5 }{0.85+ 0.7} = 3.9 $$ \n",
    "\n",
    "In general, for a user $u$ the estimated score on item $i$ is given by\n",
    "$$ \\hat{r}_{u,i} = \\frac{\\sum_{v \\in N_u^K} {\\rm sim}(u,v) ~r_{v,i} }{\\sum_{v \\in N_u^K} {\\rm sim}(u,v)} $$\n",
    "where $N_u^K$ are the $K$ most similar neighbours to the user $u$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQFrtNQlHASQ"
   },
   "source": [
    "Although in this example users are rating items on a scale between 0 and 5, there is no guarantee that all users will interpret the scale equally or that some users will be more or less generous in their ratings. To correct for these effects, we may find modifications to the above model by including normalised versions of the ratings.\n",
    "\n",
    "Normally, there are two variants:\n",
    "* **Average correction**: in this case, the average value of the user's scores is taken away from each score, i.e, \n",
    "$$ r_{u,i}^{norm} = r_{u,i} - \\bar{r_{u}}$$\n",
    "where $\\bar{r_{u}}$ is the mean value of the scores given by the user $u$.\n",
    "* **z-score correction**: in this case both the mean and the standard deviation are adjusted, resulting in a new rating or score called z-score that tries to make the distribution of the scores of all users the same. This new normalised score is given by:\n",
    "$$ r_{u,i}^{norm} = \\frac{r_{u,i} - \\bar{r_{u}}}{std(r_{u})}$$\n",
    "\n",
    "where $\\bar{r_{u}}$ and $std(r_{u})$ are, respectively, the mean value and the standard deviation of the ratings given by the user $u$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMtXprMJYabH"
   },
   "source": [
    "## 4.2 Content-based collaborative filtering\n",
    "\n",
    "The working principles of this system are very similar to the previous one, but we will use the similarities between objects (and not between users) to make the predictions.\n",
    "For example, going back to our example\n",
    "\n",
    "<img align=\"centre\" src=\"http://www.tsc.uc3m.es/~vanessa/Figs_notebooks/ML/SR/CF_item2item.png\" width=60%>\n",
    "\n",
    "To do this, we can measure the similarity between items $i$ and $j$ as the correlation between the ratings given by the users who have rated both items\n",
    "$${\\rm sim}(i,j) = \\frac{\\sum_{u \\in U_{i,j}}  r_{u,i}  r_{u,j}  }{\\sqrt{\\sum_{u \\in U_{i,j}} r_{u,i}^2  \\sum_{u \\in U_{i,j}}r_{u,j}^2}}$$\n",
    "\n",
    "where $U_{i,j}$ is the set of users who have rated both items. Applying this expression to our example, we see that the items most similar to Item 5 are Item 1 and Item 4. \n",
    "\n",
    "We can then use the ratings given by Alice to the set of contents similar to Item 5 ($N_{Item5}$) to make predictions:\n",
    "\n",
    "\n",
    "$$ \\hat{r}_{A,Item5} = \\frac{\\sum_{j \\in N_{Item5}} {\\rm sim}(Item5,j) r_{A,j} }{\\sum_{j \\in N_{Item5}} {\\rm sim}(Item5,j)} $$\n",
    "\n",
    "which for our example would give us that $\\hat{r}_{A,Item5}=4.7$.\n",
    "\n",
    "For a general case, the estimated rating for a user $u$ on item $i$ is given by\n",
    "$$ \\hat{r}_{u,i} = \\frac{\\sum_{j \\in N_i^K} {\\rm sim}(i,j) r_{u,j} }{\\sum_{j \\in N_i^K} {\\rm sim}(i,j)}$$\n",
    "\n",
    "where now $N_i^K$ are the $K$ most similar neighbours to item $i$.\n",
    "\n",
    "Finally, if we wish, we can also apply the mean or z-score corrections to homogenise the ranges of scores between users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgNeFtMydKmg"
   },
   "source": [
    "And now that I know some of the collaborative filtering models, how do I apply them to my book recommendation problem?\n",
    "\n",
    "We could implement these models in Python and design our own functions, but here we are going to make use of one of the most widely used Python libraries for Recommender Systems: [Surprise](http://surpriselib.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXCodQXFwGCV"
   },
   "source": [
    "#Â 5. SURPRISE\n",
    "\n",
    "The [SurPRISE](http://surpriselib.com/) library (Simple Python RecommendatIon System Engine) facilitates the design of recommendation systems (especially collaborative filtering systems) by including tools for:\n",
    "\n",
    "* Manage data (especially rating matrices). Users can use built-in datasets (Movielens, Jester) or own databases.\n",
    "* Train multiple collaborative filtering algorithms: the ones we have just seen based on neighbourhood between users or between content, as well as other collaborative filtering methods that we will see later.\n",
    "* Facilitate the evaluation, analysis and comparison of the performance of different methods. \n",
    "* Perform parameter tuning. This includes cross-validation procedures.\n",
    "\n",
    "All these methods or tools have a very similar syntax to those of sklearn, so they are very easy to use.\n",
    "\n",
    "Let's see how to work with this library on our example. Let's start by installing Surprise in Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AFnbutJiPOMb",
    "outputId": "4c811a3d-ddd9-41bd-9f40-b024d2313319"
   },
   "outputs": [],
   "source": [
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3z51kM3Q6Qi"
   },
   "source": [
    "## 5.1. Loading and preprocessing data in Surprise\n",
    "\n",
    "To load a dataset from a dataframe into *Surprise*, we can use the `load_from_df()` method. To do this, we need a dataframe with three columns (in this order): \n",
    "* user ids,\n",
    "* content ids,\n",
    "* assigned scores/ratings.\n",
    "\n",
    "In addition, this function uses a `Reader` object where we have to specify with the `rating_scale` parameter the range of the rating values (in our case from 1 to 10).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6lF4udwQ2Da"
   },
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset\n",
    "\n",
    "reader = Reader(rating_scale=(1,10))\n",
    "data = Dataset.load_from_df(rating[['userID', 'bookID', 'bookRating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GESFnKSIopNh"
   },
   "source": [
    "Let's see the before and after..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "GYqZoOJvouad",
    "outputId": "51a5aaba-a7d7-47e4-d5d0-5fc93dfbcbf4"
   },
   "outputs": [],
   "source": [
    "rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UtShj1TsoySI",
    "outputId": "4388652b-d980-4f72-cf3a-3301e5f3a214"
   },
   "outputs": [],
   "source": [
    "print(type(data))\n",
    "data.raw_ratings[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGfhaV8fnY5O"
   },
   "source": [
    "*Note*: The last column is used in datasets that have predefined partitions, in our case there are none and their values are set to `None`.\n",
    "\n",
    "To train our model, as when working with classification/regression models, it is appropriate to split the training set into training and test partitions. To do this we can use the `train_test_split()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHum8CTznxVE"
   },
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQBpHmEom8U0"
   },
   "source": [
    "Looking at this code, everything looks very simple and similar to our working procedure in sklearn. But **be careful**, Surprise handles different data types, and when we apply these conversions it generates different data types and it uses internal indexes for users and items..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cMvNCQuQl-ds",
    "outputId": "9246e1ef-0a1b-4c38-8057-8d3486a229c6"
   },
   "outputs": [],
   "source": [
    "print(type(trainset))\n",
    "# This object allows to obtain the tuples (id_u, id_i, rating) with the .all_ratings() method.\n",
    "print('Rating values')\n",
    "print(list(trainset.all_ratings())[:10])\n",
    "# We can use the functions .to_raw_iid(), .to_raw_uid to convert the internal ids to the original ones.\n",
    "# Or the functions .to_inner_iid() and .to_inner_uid() to undo this conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-bVwh_5Ql196",
    "outputId": "9296b3b3-d951-48e4-8355-c1432f07d90c"
   },
   "outputs": [],
   "source": [
    "print(type(testset))\n",
    "testset[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBRcEQ8Ms3ur"
   },
   "source": [
    "As we will see, these objects, `trainset` and `testset`, are the ones used, respectively, by the `.fit()` and `.predict()` methods of the different models. If we want to train a model with the original dataset, we would have to convert the `surprise.dataset.DatasetAutoFolds` data type to `surprise.trainset.Trainset` or we will have to turn it into a `list` if we want to make predictions. This can be done with the functions `build_full_trainset()` and `build_testset()` or `build_anti_testset()` as shown in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3iv0XbEtvXV",
    "outputId": "39ec28f9-1aab-4ce3-af4d-ed2bf625b775"
   },
   "outputs": [],
   "source": [
    "# To check we print the number of ratings in data\n",
    "print('Original data')\n",
    "print(len(data.raw_ratings))\n",
    "\n",
    "# We generate a set of ratings with the training data.\n",
    "trainset_all = data.build_full_trainset()\n",
    "print('Training data')\n",
    "print(type(trainset_all))\n",
    "print(trainset_all.n_ratings)\n",
    "\n",
    "# We generate a test set with the training data (to compute training  performance).\n",
    "testset_all = trainset_all.build_testset()\n",
    "print('Test data (with the taining samples)')\n",
    "print(type(testset_all))\n",
    "print(len(testset_all))\n",
    "\n",
    "# We generate a test set with the data that are not in training. \n",
    "# (all combinations of unrated users and items) \n",
    "testset_all_anti = trainset_all.build_anti_testset()\n",
    "print('Test data (with data that are not in training)')\n",
    "print(type(testset_all_anti))\n",
    "print(len(testset_all_anti))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7DQ3dYjnSl9"
   },
   "source": [
    "## 5.2 Training a model\n",
    "\n",
    "As Sklearn, to train a model we just need to define the model with its constructor and then use the `.fit()` method to train it. To train a model based on neighbours, Surprise includes the following methods:\n",
    "\n",
    "* [`KNNBasic`](https://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNBasic): this is the basic collaborative filtering algorithm we have seen before. It implements collaborative filtering based on users or content as defined by the `user_based` parameter of [`sim_options`](https://surprise.readthedocs.io/en/stable/prediction_algorithms.html#similarity-measures-configuration).\n",
    "\n",
    "* [`KNNWithMeans`](https://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNWithMeans): the same algorithm as above but with mean correction.\n",
    "\n",
    "* [`KNNNWithZScore`](https://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNWithZScore): the same algorithm as the previous ones but with mean and standard deviation correction.  \n",
    "\n",
    "When defining these models, Surprise allows us to select two parameters that affect the neighbourhood used to make the predictions. If we remember that the predictions are given by:\n",
    "\n",
    "$$ \\hat{r}_{u,i} = \\frac{\\sum_{v \\in N_u^K} {\\rm sim}(u,v) r_{v,i} }{\\sum_{v \\in N_u^K} {\\rm sim}(u,v)} $$\n",
    "\n",
    "where $N_u^K$ are the $K$ most similar neighbours to the user $u$, Surprise lets us control this neighbourhood with these parameters:\n",
    "* `k`: number of neighbours (users/items) that are considered to make the prediction (this is the size of the set $N_u^K$). If a user has more neighbours, only the `k` most similar are used. And if it has fewer, only those are used, unless they are less than `k_min`.\n",
    "* `k_min`: minimum number of required neighbours of a user/item to make a prediction. For users/items with less than `k_min` neighbours, their predictions are maded based on their average ratings, i.e. on $\\bar{r}_{u}$ or  $\\bar{r}_{i}$.\n",
    "\n",
    "Moreover, the class [`sim_options`](https://surprise.readthedocs.io/en/stable/prediction_algorithms.html#similarity-measures-configuration) not only allows us to select a model based on either users or contents, but also allows us to define several metrics, imported from the [`similarities`](https://surprise.readthedocs.io/en/stable/similarities.html#module-surprise.similarities) module, to find the most similar users or items to a given one. Specifically, it includes 4 metrics:\n",
    "\n",
    "* `cosine`: Calculates the cosine similarity between all pairs of users (or items). For example, between users $u$ and $v$ this measure would be:\n",
    "$${\\rm sim}(u,v) = \\frac{\\sum_{i \\in I_{u,v}}  r_{u,i}  r_{v,i}  }{\\sqrt{\\sum_{i \\in I_{u,v}} r_{u,i}^2  \\sum_{i \\in I_{u,v}}r_{v,i}^2}}$$\n",
    "where $I_{u,v}$ is the set of items that both users have scored.\n",
    "\n",
    "* `msd`: Calculates the similarity as the inverse of the root mean square distance between all pairs of users (or items). In this case the similarity between users $u$ and $v$ is given by:\n",
    "$${\\rm sim}(u,v) = \\frac{1}{1 + \\sum_{i \\in I_{u,v}}  \\left(r_{u,i} - r_{v,i} \\right)^2}$$\n",
    "where a $+1$ term is included in the denominator to avoid divisions by $0$.\n",
    "\n",
    "* `pearson`: Calculates the Pearson correlation coefficient between all pairs of users (or items), given by:\n",
    "$${\\rm sim}(u,v) = \\frac{\\sum_{i \\in I_{u,v}}  \\left(r_{u,i} - \\bar{r_{u}}\\right)  \\left(r_{v,i}- \\bar{r_{v}} \\right) }{\\sqrt{\\sum_{i \\in I_{u,v}} \\left(r_{u,i} - \\bar{r_{u}}\\right)^2  \\sum_{i \\in I_{u,v}} \\left( r_{v,i} - \\bar{r_{v}}\\right)^2}}$$\n",
    "where $\\bar{r_{u}}$  and $\\bar{r_{v}}$ are the mean values of the user ratings $u$ and $v$.\n",
    "\n",
    "* `pearson_baseline`: This is the same measure as before, except that instead of subtracting the averages from the ratings, it subtracts some mean coefficients that must be learnt (we will see later how to learn them). In addition, it includes a correction (*shrinkage*) to avoid overfitting effects when there are few common elements between users $u$ and $v$. With these changes this measure is given by:\n",
    "$${\\rm sim}(u,v) =\\frac{\\mid I_{u,v} \\mid -1}{\\mid I_{u,v} \\mid -1+Sh} \\frac{\\sum_{i \\in I_{u,v}}  \\left(r_{u,i} - {b_{u}}\\right)  \\left(r_{v,i}- {b_{v}} \\right) }{\\sqrt{\\sum_{i \\in I_{u,v}} \\left(r_{u,i} - {b_{u}}\\right)^2  \\sum_{i \\in I_{u,v}} \\left( r_{v,i} - {b_{v}}\\right)^2}}$$\n",
    "where ${b_{u}}$ and ${b_{v}}$ are the  mean coefficients of users $u$ and $v$ (which we will have to learn) and $Sh$ is the *shrinkage* coefficient which is a model parameter to be defined.\n",
    "\n",
    "In addition, the similarity calculation includes the parameter `min_support` which indicates the minimum number of common items for the similarity to be calculated. If two users (or two items) do not have a minimum of `min_support` common elements scored, their similarity will be 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XHaRpCvnX5B"
   },
   "source": [
    "Now that we know the models included in Surprise, let's see how to define and train one of these models. Let's start with the simplest model, the `KNNBasic` with its default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9LfpZynms1MK",
    "outputId": "0523d71e-0af9-4172-faf0-0dbd8298abad"
   },
   "outputs": [],
   "source": [
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "\n",
    "KNNalgo = KNNBasic()\n",
    "KNNalgo.fit(trainset)\n",
    "\n",
    "# Check the model parameters\n",
    "print(KNNalgo.k)\n",
    "print(KNNalgo.min_k)\n",
    "print(KNNalgo.sim_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCVg35Xjn1Qq"
   },
   "source": [
    "If we want, we can modify these parameters in the constructor. For example, we can set a neighbourhood of 60 and a `k_min` value of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sRub81VoGlm",
    "outputId": "767384d1-ebeb-4313-f0ac-ce79e7599526"
   },
   "outputs": [],
   "source": [
    "KNNalgo = KNNBasic(k=60, min_k=10)\n",
    "KNNalgo.fit(trainset)\n",
    "\n",
    "# Check the model parameters\n",
    "print(KNNalgo.k)\n",
    "print(KNNalgo.min_k)\n",
    "print(KNNalgo.sim_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zw8F1HbOoS3o"
   },
   "source": [
    "We can even change the `sim_options` setting to make a content-based model using the `msd` as a measure of similarity between items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLOuOTqxonNK",
    "outputId": "f9426600-63b2-443c-f9bf-42aa212c726f"
   },
   "outputs": [],
   "source": [
    "sim_options = {'name': 'msd', 'user_based': False}\n",
    "KNNalgo = KNNBasic(k=60, min_k=10, sim_options = sim_options )\n",
    "KNNalgo.fit(trainset)\n",
    "\n",
    "# Check the model parameters\n",
    "print(KNNalgo.k)\n",
    "print(KNNalgo.min_k)\n",
    "print(KNNalgo.sim_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVHNsw-LuDaB"
   },
   "source": [
    "## 5.3 Getting predictions \n",
    "\n",
    "Once the model is trained, in Surprise we can use the method [`.predict()`](https://surprise.readthedocs.io/en/stable/predictions_module.html#surprise.prediction_algorithms.predictions.Prediction) to get the prediction of a particular item for a given user. Or if we want to get the predictions for a test set (several users and items at once) we can use the `.test()` method. \n",
    "\n",
    "\n",
    "If we activate the `verbose` of the `predict` method, it returns information about the prediction. This information includes the actual value (if we tell it to do so when we call it), the predicted value and a `PredictionImpossible` flag that tells us if the prediction was possible. For example, in KNN methods if there are not enough neighbours (`min_k`) the prediction cannot be made and this method returns this exception and as  prediction provides the average value of the ratings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSG0OY5__rzO"
   },
   "source": [
    "#### **Exercise 7**: \n",
    "Estimate the rating of the first 4 items in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntSj7-EcKrJg"
   },
   "source": [
    "####Â Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ctVObPq__yGa",
    "outputId": "3e3cdac6-5217-414b-d7bd-634b3089d789"
   },
   "outputs": [],
   "source": [
    "# Check the four first elements in the test dataset\n",
    "testset[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RCqfomhCAeUo",
    "outputId": "8a79f259-0b63-42a3-ba7a-f9afb77bc28c"
   },
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bDysHcLDB2HJ",
    "outputId": "4b3f0abe-be04-449e-89a4-fe3f243b7e63"
   },
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v33Nxc-4DlfK"
   },
   "source": [
    "#### **Exercise 8**:\n",
    "Estimate the ratings of the whole test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlVizHioKuRh"
   },
   "source": [
    "####Â Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0foPy5X_wX9",
    "outputId": "9cf648ea-2c29-42d8-c67c-50de6c1679e3"
   },
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F77dUVAmnLGE"
   },
   "source": [
    "## 5.4. Evaluating the model\n",
    "\n",
    "Once we have the model predictions, we can use some of the following measures or metrics in the [accuracy](https://surprise.readthedocs.io/en/stable/accuracy.html) module to evaluate the model performance. In particular there are 4 measures to evaluate the error:\n",
    "\n",
    "* `rmse`: Calculates the root mean squared error (RMSE, *Root Mean Squared Error*):\n",
    "$$ RMSE = \\sqrt{{1}{N} \\sum_{i=1}^N (p_i -r_i)^2}$$\n",
    "* `mse`: Calculates the mean squared error (MSE, *Mean Squared Error*):\n",
    "$$ MSE = \\frac{1}{N} \\sum_{i=1}^N (p_i -r_i)^2$$\n",
    "* `mae`: Calculates the mean absolute error (MAE, *Mean Absolute Error*):\n",
    "$$MAE = \\frac{1}{N} \\sum_{i=1}^N |p_i -r_i|$$\n",
    "* `fcp`: Calculates the fraction of concordant pairs (FCP, *Fraction of Concordant Pairs*). This measure is oriented to evaluate a ranking result and not the accuracy of the estimated vs the actual rating values. To do so, they measure the number of concordant pairs per user by counting the number of pairs:\n",
    "$$n^u_c=\\mid \\{(i,j), ~ \\hat{r}_{u,i}>\\hat{r}_{u,j} ~~\\rm{y} ~~~{r}_{u,i}>{r}_{u,j}\\}\\mid$$\n",
    "and equivalently evaluate the number of discordant pairs $n^u_d$. Then, averaging these values over all users, $n_c = \\sum_u n^u_c$ and $n_d = \\sum_u n^u_d$, the FCP is defined as:\n",
    "$$ FCP = \\frac{n_c}{n_c+n_d}$$\n",
    "\n",
    "To use these metrics we only need to call the corresponding function within the `accuracy` module by giving it the set of predictions we have estimated (note that in these predictions the actual rating values are also included, so the error can be calculated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7LKUE2RNj5Dm",
    "outputId": "16cdf6a8-4532-4326-cd83-60ba1063d694"
   },
   "outputs": [],
   "source": [
    "from surprise import accuracy\n",
    "\n",
    "# Compute performance \n",
    "RMSE = accuracy.rmse(predictions)\n",
    "\n",
    "MSE = accuracy.mse(predictions)\n",
    "\n",
    "MAE = accuracy.mae(predictions)\n",
    "\n",
    "FCP = accuracy.fcp(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21ptVT-TEQTE"
   },
   "source": [
    "## 5.5 Analysis of the influence of model parameters\n",
    "\n",
    "So far, we have trained a simple KNN model, based on similarities between users, and we have used its default parameters.\n",
    "\n",
    "In this section, we will see how the values of `K` and `k_min` influence on the model performance, the differences using a model based on user or content similarity, as well as the impact of using different similarity measures. Finally, we will see whether using other versions of the KNN model, such as those that include mean or z-score corrections, can provide advantages.\n",
    "\n",
    "To do so, please complete the following exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Csm7YGeeMp7v"
   },
   "source": [
    "#### **Exercise 9**:\n",
    "Analyse the influence of the value of `k` in the `KNNBasic` model (keep the remaining  parameters to their default values). Explore values in the range $[10,20,30,40,50]$ and measure the model performance in terms of RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tv51mD8ZMs6z"
   },
   "source": [
    "####Â Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 775
    },
    "id": "-OwHWXarEPmI",
    "outputId": "cae14f71-02a8-4ead-9c9e-1262bc3b22b7"
   },
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpNxEl38NapZ"
   },
   "source": [
    "#### **Exercise 10**:\n",
    "Analyse the influence of the value of `min_k` on the `KNNBasic` model (set `k` to the best value from the previous section and keep the reamining parameters to their default values). Explore values in the range 1 to 20 and measure performance in terms of RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWTdeu1aN0_Q"
   },
   "source": [
    "####Â Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TFrIp2Hpj49_",
    "outputId": "7cb4b4ed-fcca-4f24-de49-f0d642124f09"
   },
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAYV5iC2N90y"
   },
   "source": [
    "#### **Exercise 11**:\n",
    "Analyse the differences between using a user-based or content-based model and, in addition, the influence of using different similarity measures (`msd`, `cosine`, `pearson`, `pearson_baseline`). You can set `k` and `min_k` to the best values from the previous sections. Again, measure performance in terms of RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3slDuMA2ObuG"
   },
   "source": [
    "####Â Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hPv2wlgH8jrh",
    "outputId": "52db2596-03ce-418c-abba-05ee59fde755"
   },
   "outputs": [],
   "source": [
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39pxCfe8PLXx"
   },
   "source": [
    "#### **Exercise 12**:\n",
    "Finally, analyse whether the modified versions of the `KNNBasic` model (`KNNWithMeans` and `KNNWithZScore`) provide any advantages over the basic model. You can use for this analysis the best parameter settings obtained in the previous sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTazD_1bPqQg"
   },
   "source": [
    "####Â Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PcqkKw6OOf1W",
    "outputId": "61437984-db80-470c-c148-b045c4a71cf6"
   },
   "outputs": [],
   "source": [
    "from surprise.prediction_algorithms import KNNBasic, KNNWithMeans, KNNWithZScore\n",
    "\n",
    "#<SOL>\n",
    "#</SOL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkQqdYHsvK-5"
   },
   "source": [
    "## 5.6 Parameter validation\n",
    "\n",
    "Surprise provides several tools to run cross-validation procedures to find the best parameters for a given algorithm. The tools are easy to use, as they follow the sklearn format.\n",
    "\n",
    "On the one hand, it has functions to generate training and test partitions (like the one we have used above) or to generate different validation partitions within the training set (in this [link](https://surprise.readthedocs.io/en/stable/model_selection.html#module-surprise.model_selection.split) you can find a detail of all of them).\n",
    "\n",
    "On the other hand, similar to sklearn  `GridSearch` module, Surprise includes the `GridSearchCV` function that allows us to define a model, the parameters to explore and it does all the magic for us.\n",
    "\n",
    "To see how it works, let's train a basic neighbourhood recommendation model (`KNNBasic`) based on content (`'user_based': False`) and select by CV the number of neighbours (`k`) and the minimum number of neighbours (`min_k`). \n",
    "\n",
    "Note: The Gridsearch function is designed to work with data of type `surprise.dataset.DatasetAutoFolds`. So, for this example, we will forget about the training/test partitions we have created and we will validate the model using all the data in `data`. Later we will see how we can use our training and test partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OfuKYoFM0pQA",
    "outputId": "fc9404cc-11e5-4115-b32d-ee6ba80d8846"
   },
   "outputs": [],
   "source": [
    "from surprise.model_selection.search import GridSearchCV\n",
    "\n",
    "param_grid = {'k': range(10,50,10), 'min_k': range(1,10),\n",
    "              'sim_options': {'name': ['cosine'],\n",
    "                              'user_based': [False]}}\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse', 'mse'], cv=3)\n",
    "\n",
    "gs.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jT_-U9Hz6F1a"
   },
   "source": [
    "We can analyse the results of the CV process by analysing the content of `cv_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "W0b0UEEfzxpq",
    "outputId": "db865ae2-9da1-4160-8e33-d9514a146e4a"
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict(gs.cv_results)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcvlRC9w6RtC"
   },
   "source": [
    "Or we can directly see the best result and optimal parameters in `best_score` and `best_params`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TCBVo0tC6TNJ",
    "outputId": "b31472d3-cbbd-4099-bc45-79c9dc8d16e9"
   },
   "outputs": [],
   "source": [
    "# Mejor RMSE \n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# Parametros Ã³ptimos\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0V2iP646dMj"
   },
   "source": [
    "If we want to apply a CV process using train/test partitions as we have done so far, we cannot use the `trainset` and `testset` objects with `GridsearchCV`. So we have to create our own dataset objects with train and test partitions. The following example shows how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kTItCDf5xsyJ",
    "outputId": "c48c174f-bf9f-4c2d-9573-8feaa9320117"
   },
   "outputs": [],
   "source": [
    "import random      \n",
    "import copy                                                        \n",
    "\n",
    "# We start with the complete dataset in dataset\n",
    "raw_ratings = data.raw_ratings                                             \n",
    "\n",
    "# We randomise the ratings (to generate random partitions)                                \n",
    "random.shuffle(raw_ratings)                                                \n",
    "\n",
    "# 75% trainset, 25% testset                                                \n",
    "threshold = int(.75 * len(raw_ratings))                                     \n",
    "trainset_raw_ratings = raw_ratings[:threshold]                             \n",
    "test_raw_ratings = raw_ratings[threshold:]                                 \n",
    "\n",
    "datatrain = copy.deepcopy(data)\n",
    "datatrain.raw_ratings = trainset_raw_ratings  \n",
    "\n",
    "#datatest = copy.deepcopy(data)\n",
    "#datatest.raw_ratings = test_raw_ratings  \n",
    "                                                     \n",
    "# We apply CV with our new Dataset that has only the train partition.   \n",
    "print('GRID SEARCH...')         \n",
    "\n",
    "param_grid = {'k': range(10,50,10), 'min_k': range(1,10),\n",
    "              'sim_options': {'name': ['msd'],\n",
    "                              'user_based': [False]}}\n",
    "# We set refit=True to re-train the final model with the whole dataset.                         \n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=3, refit= True)\n",
    "gs.fit(datatrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sIMQOqhw-Ut6",
    "outputId": "bb249335-7e6f-44c0-d111-25837c6cae65"
   },
   "outputs": [],
   "source": [
    "# Ahora evaluamos en el conjunto de test                                            \n",
    "testset_gs = data.construct_testset(test_raw_ratings)      \n",
    "predictions = gs.test(testset_gs)\n",
    "print('RMSE en la particion de test:')                                          \n",
    "RMSE = accuracy.rmse(predictions)                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jvwq_rJ8unh9"
   },
   "source": [
    "## 5.7 Limitations of neighbourhood-based models\n",
    "\n",
    "* How can we make recommendations to new users of the system or to new content? This is known as the **cold-start-problem** and the solution is to create hybrid systems that combine collaborative filtering systems with systems based on popularity, user or content. For example:\n",
    "  * The problem of new users can be alleviated with a hybrid system that incorporates user demographic information to find similar users. Or asking new users for rating a minimum number of objects before the system can start working.\n",
    "  * The problem of new content can also be alleviated by hybrid systems that, in this case, incorporate metadata information of the contents. Or by asking users for rating new items (and giving them some reward for doing so).\n",
    "\n",
    "* And even if users and content are not new, sometimes the ratings they have are too few to make good estimates and ratings are directly estimated by averages. Surprise includes a threshold on the minimum number of common scores between two users or items that are arequired to calculate similarities. \n",
    "\n",
    "* Computational cost of these models. As we have seen how these models work, to estimate the score of a user $u$ for an item $i$, we need to calculate the users who are similar to user $u$ (in a user-based model) or contents that are similar to item $i$ (in the content-based model). This computation is computationally expensive as it requires calculating the distances between all users or items (by accessing all scores of all users or items) in order to make an estimate; these models are known as **memory-based** and can only be used (from a practical point of view) if the database is not very large. To overcome this limitation, it is sometimes proposed to pre-compute these distances (knowing which users or items are similar to a given one), generating a **model-based** system, and then only averaging scores to predict new ratings. This scheme tends to work very well in content-based neighbourhood models since the similarities between items do not tend to vary over time; in fact, this is the scheme used by Amazon in its recommendation system and it is able to make recommendations on millions of products in a very efficient way.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfUCtHPbUcqU"
   },
   "source": [
    "## 6. Collaborative Filtering Models based on latent or factorial decompositions\n",
    "\n",
    "## 6.1. Introduction \n",
    "\n",
    "In latent factor models users and items are mapped to a lower dimensional space. Their new vector representation, in this new space, is called latent. Let's see this process with the example from before:\n",
    "\n",
    "<img align=\"center\" src=\"http://www.tsc.uc3m.es/~vanessa/Figs_notebooks/ML/SR/Factorizacion1.pdf\" width=80%>\n",
    "\n",
    "This latent representation has several advantages:\n",
    "1. By having the latent representation of the users and items, we can reconstruct (or estimate) the matrix of scores. \n",
    "\n",
    "<img align=\"center\" src=\"http://www.tsc.uc3m.es/~vanessa/Figs_notebooks/ML/SR/Factorizacion2.pdf\" width=80%>\n",
    "\n",
    "2. This new representation of users and items can help to interpret the predictions:\n",
    "\n",
    "<img align=\"centre\" src=\"http://www.tsc.uc3m.es/~vanessa/Figs_notebooks/ML/SR/latent-factors.png\" width=50%>\n",
    "\n",
    "(*) Figure from https://kevinkolcheck.com/wp-content/uploads/2017/12/latent-factors.png\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAu5wnOQyuGW"
   },
   "source": [
    "And how can we obtain this latent representation? With the **Alternating Least Squares** (ALS) algorithm. \n",
    "\n",
    "The ALS algorithm tries to approximate the rating matrix by factoring it as the product of two matrices: \n",
    "\n",
    "$$ R = X * Y $$\n",
    "\n",
    "where $X$ and $Y$ are the latent factor matrices describing the properties of each user and each item, respectively.\n",
    "\n",
    "These matrices are computed to minimise the mean squared error between the predictions and the actual ratings over the known ratings (those of our training set):\n",
    "\n",
    "$$ \\min_{X, Y} \\sum_{(u, i) \\in P} \\left( r_{u,i} - \\bf{x}_u^{\\top} \\bf{y}_i \\right)^2 + \\lambda \\left( ||X||^2 + ||Y||^2 \\right)\n",
    "$$\n",
    "\n",
    "where P is the set of elements with known rating.\n",
    "\n",
    "To find the solution to this problem, the ALS algorithm starts by randomly initialising the latent factor matrices $X$ and $Y$ and then, considering the values of $Y$ are known, optimises the values of $X$ such that :\n",
    "\n",
    "$$ \\min_{X} \\sum_{(u, i) \\in P} \\left( r_{u,i} - \\bf{x}_u^{\\top} \\bf{y}_i \\right)^2 + \\lambda ||X||^2 $$\n",
    "\n",
    "Then, with the latent factors obtained for the users ($X$), the latent values of the items are optimized:\n",
    "$$ \\min_{Y} \\sum_{(u, i) \\in P} \\left( r_{u,i} - \\bf{x}_u^{\\top} \\bf{y}_i \\right)^2 + \\lambda |||Y|||^2 $$\n",
    "\n",
    "Iterating over these two steps until the algorithm converges, we reach the final lantent factor for users and items.\n",
    "\n",
    "The fact that this algorithm alternates between a problem in $X$ and a problem in $Y$ is what makes this method called *Alternating Least Squares*.\n",
    "\n",
    "This method is a collaborative filtering system with model, since it performs a previous training where it calculates the latents and to make predictions it only needs to do the product of the associated latents (it does not need to re-access the whole rating matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmD8qdNxyyDG"
   },
   "source": [
    "## 6.2. Latent models in Surprise\n",
    "\n",
    "Surprise includes the implementation of this model within the [SVD](https://surprise.readthedocs.io/en/stable/matrix_factorization.html) module where it provides a more generalised implementation; instead of considering that a score is estimated by the product of its associated latents ($\\hat{r}_{u,i} = \\bf{x}_u^{\\top} \\bf{y}_i$) the predictions are considered to be given by this model:\n",
    "$$\\hat{r}_{u,i} = \\mu +  b_u + b_i + \\bf{x}_u^{\\top} \\bf{y}_i$$\n",
    "\n",
    "where $\\mu$ is the mean of the scores, ${b_{u}}$ and ${b_{i}}$ are the coefficients of means of user $u$ and item $i$, and $\\bf{x}_u$ and $\\bf{y}_i$ are the latent variables of user $u$ and item $i$. To learn all these parameters, Surprise minimises the mean squared error (as the generic ALS does), but using this new definition of  $\\hat{r}_{u,i}$ and learning all the parameters together. \n",
    "\n",
    "However, the model includes a `biased` parameter that we can set to `False` if we want to remove all these biasing factors and recover the original ALS model. In addition, this model includes as input parameter the number of latents (number of components in the vectors $\\bf{x}_u$ and $\\bf{y}_i$), which we will have to specify through the parameter `n_factors` and as we will see will be critical to obtain good performance with this model.\n",
    "\n",
    "Finally, Surprise includes the SVD method and has two variants of it ([SVDpp](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVDpp) and [NMF](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.NMF)) that allow, respectively, to work with implicit scores and to impose different restrictions on the latent factors. If you are interested and want to go deeper into these models, you can check the library documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ouc6wWODtqxH"
   },
   "source": [
    "## 6.2.1 Training and evaluation of the model\n",
    "\n",
    "We start by training the SVD model with all its default parameters and evaluating its performance. To do this, we are going to reuse the training and test partitions we had."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ot7MrHD2D9vR",
    "outputId": "ecf6f42f-75bc-480d-8917-1d1ca1fe1211"
   },
   "outputs": [],
   "source": [
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "\n",
    "algoLatent = SVD()\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algoLatent.fit(trainset)\n",
    "predictions = algoLatent.test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRXam02eukk1"
   },
   "source": [
    "As we can see, without adjusting any parameter, this model is already giving performances below 1.58 (best result so far). Let's now see how this method behaves using or not the biasing factors and how the number of latents influences its performance. To do so, complete the following exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xs-eB4EG18jJ"
   },
   "source": [
    "#### **Exercise 13**:\n",
    "Analyse the performance of the SVD algorithm, in terms of RMSE, in its basic version (without biasing factors, `biased = False`) for different number of latents. You can explore values of this parameter in the range from 1 to 100 with steps of 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XK_jRPvl2exG"
   },
   "source": [
    "####Â Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 986
    },
    "id": "EFv7kgUXD9rV",
    "outputId": "d7c94f6b-79c2-401c-dcef-3458e6ddd530"
   },
   "outputs": [],
   "source": [
    "# We evaluate the evolution of the RMSE with the number of latents and without mean corrections.\n",
    "range_nlatents =  range(1,100, 5)\n",
    "RMSE_nlatents = []\n",
    "for nlatents in range_nlatents:\n",
    "  print('Value of nlatents: ' + str(nlatents))\n",
    "  #<SOL>\n",
    "  #</SOL>\n",
    "plt.figure()\n",
    "plt.plot(range_nlatents, RMSE_nlatents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MiIgCIA42sHS"
   },
   "source": [
    "#### **Exercise 14**:\n",
    "Repeat the previous exercise using the mean factors (`biased = True`) and analyse the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 986
    },
    "id": "XJ4LBKZ8D9m-",
    "outputId": "facabc94-cec4-46e1-a855-5678a68a5c62"
   },
   "outputs": [],
   "source": [
    "# We evaluate the evolution of the RMSE with the number of latents and with mean corrections.\n",
    "\n",
    "range_nlatents =  range(1,100, 5)\n",
    "RMSE_nlatents = []\n",
    "for nlatents in range_nlatents:\n",
    "  print('Value of nlatents: ' + str(nlatents))\n",
    "  #<SOL>\n",
    "  #</SOL>\n",
    "plt.figure()\n",
    "plt.plot(range_nlatents, RMSE_nlatents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzyLqaMN3jV-"
   },
   "source": [
    "**Conclusions**: As we can see, it seems that the full model (with mean factors) tends to show better results and to be less dependent on the number of latents used. Whereas in the previous case, the choice of the number of latents is critical (in this database using few latents gives good results, but this is **not** the usual scenario). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyiJGAp-3Nrv"
   },
   "source": [
    "### 6.2.2 Parameter validation\n",
    "\n",
    "Let's analyze the model performance  by selecting this parameter (`n_factors`) with cross-validation. We will use our approach to redefine the training and test partitions in order to compare with the results obtained so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KeA-nX7d3ifW",
    "outputId": "2eb26ea1-4a8f-4fbe-9a4a-f4b4144e6939"
   },
   "outputs": [],
   "source": [
    "# Usamos las variables datatrain y testset_gs que definimos antes\n",
    "\n",
    "param_grid = {'n_factors': range(1,100, 5), 'biased': [True]}\n",
    "\n",
    "# Fijamos refit=true para que reentrene el modelo final con todo el conjunto de datos                         \n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3, refit= True)\n",
    "gs.fit(datatrain)\n",
    "\n",
    "# Ahora evaluamos en el conjunto de test                                            \n",
    "testset_gs = data.construct_testset(test_raw_ratings)      \n",
    "predictions = gs.test(testset_gs)\n",
    "print('RMSE en la particion de test:')                                          \n",
    "RMSE = accuracy.rmse(predictions)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80VtNBW26FAC"
   },
   "source": [
    "### 6.2.3 Latent analysis\n",
    "\n",
    "Let's now analyse the latents obtained. To do so, we will train a model with only two latents and we will represent items in this (two-dimensional) latent space.\n",
    "\n",
    "We can carry out a similar analysis with the users, but we do not have information about them to be able to extract any conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Vm8JtAj3iah"
   },
   "outputs": [],
   "source": [
    "algoLatent = SVD(n_factors = 2, biased=False, random_state =20)\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algoLatent.fit(trainset)\n",
    "\n",
    "X = algoLatent.pu\n",
    "Y = algoLatent.qi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Py1PDYb03iPE",
    "outputId": "18454c87-dc65-47ea-d0d3-3655a9339cf3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "items_id_Y = np.array([trainset.to_raw_iid(id) for id in trainset.all_items()])\n",
    "latentsY = np.concatenate((items_id_Y[:, np.newaxis], Y), axis=1)\n",
    "\n",
    "pd_items_id_Y = pd.DataFrame(latentsY, columns = ['bookID', 'Y0', 'Y1'])\n",
    "pd_items_id_Y.Y0 = pd_items_id_Y.Y0.astype(float)\n",
    "pd_items_id_Y.Y1 = pd_items_id_Y.Y1.astype(float)\n",
    "pd_items_id_Y = pd.merge(pd_items_id_Y, books[['bookID','title', 'year']], on='bookID', how='inner')\n",
    "pd_items_id_Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "77iN9mrDI22c",
    "outputId": "2f0cdbcb-49b0-405f-936d-51e373155c27"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "\n",
    "\n",
    "pd_items_id_Y = pd_items_id_Y.loc[pd_items_id_Y.year>1998]\n",
    "# Point size related to the year\n",
    "years = pd_items_id_Y.year.values\n",
    "scale = 2*(years - 1994)\n",
    "ax.scatter(pd_items_id_Y.Y0.values, pd_items_id_Y.Y1.values, c='blue', s=scale, label='Items')\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "titles = pd_items_id_Y.title.values\n",
    "#for i, txt in enumerate(titles):\n",
    "for i, txt in enumerate(titles[:100]):\n",
    "    ax.annotate(txt, (pd_items_id_Y.Y0.values[i], pd_items_id_Y.Y1.values[i]), label='Title')\n",
    "\n",
    "\n",
    "#ax.scatter(X[:, 0], X[:, 1], s=3, c='red')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvnklaPYzv6-"
   },
   "source": [
    "# Other models included in Surprise\n",
    "\n",
    "**Random score generator**.\n",
    "\n",
    "It considers that the scores follow a Gaussian distribution with mean $\\mu$ and variance $v$ and when it is asked for a prediction, it generates a random value from that distribution.\n",
    "\n",
    "The values of $\\mu$ and $v$ are calculated from the sample means and variances of the scores in the training set.\n",
    "\n",
    "[NormalPredictor](https://surprise.readthedocs.io/en/stable/basic_algorithms.html#surprise.prediction_algorithms.random_pred.NormalPredictor)\n",
    "\n",
    "**Mean-based generator**\n",
    "\n",
    "This model assumes a user rating for an item is given by:\n",
    "\n",
    "$$r_{u,i} = \\mu + b_u + b_i$$\n",
    "\n",
    "As you can see, this model is a simplified version of the SVD and the learning of these parameters is also done using the ALS.\n",
    "\n",
    "[BaselineOnly](https://surprise.readthedocs.io/en/stable/basic_algorithms.html#surprise.prediction_algorithms.baseline_only.BaselineOnly)\n",
    "\n",
    "**K-NN with baseline**\n",
    "\n",
    "Modifies the neighbourhood-based model by including mean estimates. That is, using the above model carries out a first estimation of the ratings:\n",
    "$$b_{u,i} = \\mu + b_u + b_i$$\n",
    "\n",
    "And then these estimatimations are used as a mean correction to estimate the ratings with a neighbourhood approximation\n",
    "\n",
    "$$ \\hat{r}_{u,i} = b_{u,i} + \\frac{\\sum_{v \\in N_u} {\\rm sim}(u,v) \\left( r_{v,i}- b_{v,i}\\right) }{\\sum_{v \\in N_u} {\\rm sim}(u,v)} $$\n",
    "\n",
    "[KNNBaseline](https://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNBaseline)\n",
    "\n",
    "**Slope One**\n",
    "In this case, the predictions are given by:\n",
    "\n",
    "$$ \\hat{r}_{u,i} = \\bar{r}_{u} + \\sum_{j \\in R_{u,i}}\\frac{dev(i,j)}{\\mid U_{i,j} \\mid} $$\n",
    "\n",
    "where $R_{u,i}$ is the set of items rated by user $u$ and where the deviation between the scores of item $i$ and item $j$, $dev(i,j)$, are measured as\n",
    "\n",
    "$$dev(i,j) = \\sum_{u \\in U_{i,j}}\\frac{r_{u,i}-r_{u,j}}{\\mid U_{i,j} \\mid}$$\n",
    "\n",
    "where $U_{i,j}$ is the set of users who have rated items $i$ and $j$, and ${\\mid U_{i,j} \\mid}$  is the number of items in this set.\n",
    "\n",
    "[SlopeOne](https://surprise.readthedocs.io/en/stable/slope_one.html#surprise.prediction_algorithms.slope_one.SlopeOne)\n",
    "\n",
    "**Co-clustering**\n",
    "\n",
    "This algorithm carries out a clustering of users and items, so you have $G$ groups of users and $H$ groups of items. For each of these groups it calculates:\n",
    "* $C_{g}$: average rating of users in the $g$-th group.\n",
    "* $C_{h}$: average rating of the items in the $h$-th group.\n",
    "* $C_{g,h}$: average rating of the ratings of the users in the $g$-th group and the items in the $h$-th group.\n",
    "\n",
    "If we further precompute the average score of each user and of each item, which we denote as $\\bar{r_{u}}$ and $\\bar{r_{i}}$, the predicion of the score of user $u$ (which belongs to group $g$) for item $i$ (which belongs to group $h$) is given by:\n",
    "$$ \\hat{r}_{u,i} = C_{g,h} + \\left(\\bar{r_{u}} -  C_{g}\\right) + \\left(\\bar{r_{i}} -  C_{h}\\right)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTDm4NB4IyVO"
   },
   "source": [
    "#Â Embeddings for colaborative filtering: Prod2Vec\n",
    "\n",
    "We have just seen how the ALS method is able to obtain a low-dimensional representation of users and products. From this representation, we can obtain estimates of the scores that users would give to items that they have not yet scored. However, this low-dimensional representation could be used for other tasks, since by having each item/user characterised with a vector we can find similarities between them, do clustering, classification, .....\n",
    "\n",
    "Another way to obtain a vector representation (embedding) of the products of our recommender system is to borrow same ideas and tools from word2vec representation to obtain embeddings of products instead of words, for that reason this approach is called Prod2Vec.\n",
    "\n",
    "Let's see how to obtain this Prod2Vec for a shopping recommendation system$^{(*)}$. To do so, let's start by loading the dataset.\n",
    "\n",
    "$^{(*)}$ This dataset is a simplified version of the challenge \"Instacart market basket analysis\" from [Kaggle](https://www.kaggle.com/c/instacart-market-basket-analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ooz6ZO4gnBhx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None # To silect warning in chained_assignment\n",
    "product_df = pd.read_csv(\"http://www.tsc.uc3m.es/~vanessa/data_notebooks/market_basket/products.csv\")\n",
    "order_product_df = pd.read_csv(\"http://www.tsc.uc3m.es/~vanessa/data_notebooks/market_basket/market_basket_red_v2.zip\").set_index('Unnamed: 0')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2dyJuWlaGhH"
   },
   "source": [
    "In this dataset we have two data tables, the first indicates the product information (it indicates what each `product_id` is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "9YPQKNMIgrJh",
    "outputId": "accb199a-d472-4ae9-cc39-36c20e0dd897"
   },
   "outputs": [],
   "source": [
    "product_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bx4FZ9jiaTqx"
   },
   "source": [
    "And on the other hand, the table with orders, for each purchase, indicates the products that have been bought and, in addition,  the order in which they are purchased. That is to say, it indicates the sequence of purchase of products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "WVTaZL7rgt7l",
    "outputId": "93d964d1-da32-49b4-ca40-40d3d1a369b6"
   },
   "outputs": [],
   "source": [
    "order_product_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rY7Jz7M3qECa"
   },
   "source": [
    "### Construction of the Prod2Vec representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BU4tvxgMhn5g"
   },
   "source": [
    "We can exploit the sequential structure given by the `order_product_df` table to see which products are usually accompanied by others, i.e., to define the context of each product. To do this, we only need to create sentence-like structures with the order in which products are purchased within the same order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "98dd7e88c8bef2cf4e8e7d014d7b7a4ec8d8101a",
    "id": "_vqqZD9Qmmkf"
   },
   "outputs": [],
   "source": [
    "order_product_list = order_product_df[['order_id','product_id']].values.tolist()\n",
    "\n",
    "product_corpus = []\n",
    "sentence = []\n",
    "new_order_id = order_product_list[0][0]\n",
    "for (order_id, product_id) in order_product_list:\n",
    "    if new_order_id != order_id:\n",
    "        product_corpus.append(sentence)\n",
    "        sentence = []\n",
    "        new_order_id = order_id\n",
    "    sentence.append(str(product_id))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kL03_nZBkbjX"
   },
   "source": [
    "Let's look at the content of these lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a80edf1212baa8b9471bff6c3fca9d69391965d9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "P-1O0FG_mmkh",
    "outputId": "3f917f38-aeda-46be-b1ce-b1a16d6afb49"
   },
   "outputs": [],
   "source": [
    "# Function to help to analyze products\n",
    "def toProductName(id):\n",
    "    id = int(id)\n",
    "    return product_df[product_df.product_id==id]['product_name'].values.tolist()[0]\n",
    "toProductName(24852)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ajho94hyi96N",
    "outputId": "6cf2de6e-4bff-4c53-8d85-2eba1b825330"
   },
   "outputs": [],
   "source": [
    "# First sentence or first shopping list\n",
    "id_list = 0\n",
    "list_products = [toProductName(id_prod) for id_prod in product_corpus[id_list]]\n",
    "print(list_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-IWA32vkPiU",
    "outputId": "ae527264-58ab-4d3b-c645-eb994b5cf9c8"
   },
   "outputs": [],
   "source": [
    "# Second sentence or first shopping list\n",
    "id_list = 1\n",
    "list_products = [toProductName(id_prod) for id_prod in product_corpus[id_list]]\n",
    "print(list_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQAwczTBkhDq"
   },
   "source": [
    "Now that we have our \"corpus\" of products or shopping lists, we can use the gensim `word2vec` function to build a `prod2vec`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bb98b4f48e72ecbeb8ad2e57ee00cdfcbe161a71",
    "id": "_i3y3iORmmkg"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(product_corpus, window=6, size=100, min_count=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "709653282ad07e272acf0dfb77f525f68ae41e17",
    "id": "C2lUUOs-mmki"
   },
   "source": [
    "### What are the most similar products?\n",
    "\n",
    "We can use the prod2vec representation or the product embedding to find similar products:\n",
    "\n",
    "* The most similar product to `banana` (24852) is ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5f7c26efb1d30c937927bcfe38e1d30bbc631b3d",
    "id": "bD7fs0vGmmki"
   },
   "outputs": [],
   "source": [
    "def most_similar_readable(model, product_id):\n",
    "    similar_list = [(product_id,1.0)]+model.wv.most_similar(str(product_id))\n",
    "    \n",
    "    return [( toProductName(int(id)), similarity ) for (id,similarity) in similar_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0dcbf0cd7cd994f0f134ae80710731bd74f0b49c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "DEa8jzL4mmki",
    "outputId": "835d0f8d-c594-456a-c595-6d23dfeea7f9"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(most_similar_readable(model, 24852), columns=['product','similarity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0a31f6d9ee8bb5a663487f216603b24f64cc2e87",
    "id": "DlOaFiNvmmkk"
   },
   "source": [
    "* The closest product to `Organic Whole Milk` (27845) is ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "51565ce4f70bcec5cd9e1bec1ec2fd6c8f139287",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "PPylPS2zmmkk",
    "outputId": "7c8e5647-7ab0-48ac-c686-814453dbecca"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(most_similar_readable(model, 27845), columns=['product','similarity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHmXC-P8SBbC"
   },
   "source": [
    "## Recommending products with prod2vec\n",
    "\n",
    "Now, we can use these similarities to design a content based colaborative filtering system.\n",
    "\n",
    "For this purpose, let's follow these steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZM_671QmSFE0"
   },
   "source": [
    "### Build the rating matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "8UAb3UWxSgir",
    "outputId": "a88b3358-1fd1-4f85-d768-85b5378df60f"
   },
   "outputs": [],
   "source": [
    "df_ratings = order_product_df.groupby(['user_id','product_id']).size().reset_index(name='ratings')\n",
    "df_ratings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTuIcb3-UPTw"
   },
   "source": [
    "### Make predictions\n",
    "\n",
    "As we already know how to compute similarities, we can directly obtain predictions.\n",
    "\n",
    "For a general case, the estimated rating for a user $u$ on item $i$ is given by\n",
    "$$ \\hat{r}_{u,i} = \\frac{\\sum_{j \\in N_i^K} {\\rm sim}(i,j) r_{u,j} }{\\sum_{j \\in N_i^K} {\\rm sim}(i,j)}$$\n",
    "\n",
    "where now $N_i^K$ are the $K$ most similar neighbours to item $i$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FWPVQE73UkBY",
    "outputId": "9d868751-428c-4d3b-8aeb-877a514de7d1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Obtain the contents included into prod2vec\n",
    "list_products =list(model.wv.vocab)\n",
    "\n",
    "# We choose a user (we can iterate it over all users)\n",
    "user_id = 206208 \t\n",
    "df_user = df_ratings.loc[df_ratings['user_id']==user_id]\n",
    "\n",
    "# We choose an item (we can iterate this over all products)\n",
    "for product_id in ['26384']:# list_products:\n",
    "  # Compute similar products to product_id and save this information                      \n",
    "  sim_products = model.wv.most_similar(product_id, topn=40)\n",
    "  df_user_sim_aux = df_user\n",
    "  df_user_sim_aux['sim']=0\n",
    "  for sim in sim_products:\n",
    "    if int(sim[0]) in df_user_sim_aux['product_id'].values:\n",
    "      df_user_sim_aux['sim'].loc[df_user_sim_aux['product_id']==int(sim[0])] = sim[1]\n",
    " \n",
    "  # We can print the similar products\n",
    "  print('List of similar products')\n",
    "  print(df_user_sim_aux.loc[df_user_sim_aux['sim']>0])\n",
    "  # Now, we can make the prediction\n",
    "  pred_rating = (df_user_sim_aux['ratings']*df_user_sim_aux['sim']).sum()/df_user_sim_aux['sim'].sum()\n",
    "  print('The predicted scoring is: %2.2f' %pred_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d51ff51e54e347192814ed41b2e8cf6c08ed60a7",
    "id": "fXdMB8h5mmkk"
   },
   "source": [
    "## Other  Applications of prod2vec: product grouping\n",
    "\n",
    "We can use the prod2vec representation to do product grouping by using it as input to a K-means. To do this we will train a k-means with 500 groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KewQQ2MHc7eX"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "K=500\n",
    "\n",
    "# Get product embeddings\n",
    "prod_emb = model.wv.vectors\n",
    "\n",
    "# Train Kmeans\n",
    "kmeans = KMeans(n_clusters=K) # Definimos objeto con parÃ¡metros por defecto\n",
    "kmeans.fit(prod_emb) # Entrenamos k-means\n",
    "y_kmeans = kmeans.predict(prod_emb) # Obtenemos el identificador del grupo para cada dato\n",
    "centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhA7RZ8teEUj"
   },
   "source": [
    "Let's analyse the resulting clusters by looking at the products most similar to each centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TuntUVz-mk8g"
   },
   "outputs": [],
   "source": [
    "def most_similar_to_centroid(model, center_emb):\n",
    "    similar_list = model.wv.similar_by_vector(center_emb)\n",
    "    \n",
    "    return [( toProductName(int(id)), similarity ) for (id,similarity) in similar_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "V5AGJxLWmQkV",
    "outputId": "3feb6d66-5972-4451-cc66-9442aba778a7"
   },
   "outputs": [],
   "source": [
    "center_id = 0\n",
    "pd.DataFrame(most_similar_to_centroid(model, centers[center_id]), columns=['product','similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "7jTDl22Rf0SD",
    "outputId": "bb7fbecd-053a-441b-ebd6-8a60460268ca"
   },
   "outputs": [],
   "source": [
    "center_id = 100\n",
    "pd.DataFrame(most_similar_to_centroid(model, centers[center_id]), columns=['product','similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "ahDacsz2nfHx",
    "outputId": "e03ad52e-a2ab-49d6-bfa7-013e4f35bd06"
   },
   "outputs": [],
   "source": [
    "center_id = 200\n",
    "pd.DataFrame(most_similar_to_centroid(model, centers[center_id]), columns=['product','similarity'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "RecommenderSystems.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
